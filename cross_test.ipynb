{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import glob\n",
    "import pickle\n",
    "from util import load_data\n",
    "\n",
    "def K_fold_split(K=5, seed=0, fold=0):\n",
    "    test_ratio = 1/K\n",
    "    random.seed(seed)\n",
    "    class_folders = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "    tatol_train_names = []\n",
    "    tatol_test_names = []\n",
    "    for i, folder in enumerate(class_folders):\n",
    "        name_list = glob.glob('data/original_data/type/%s/*.dat'%folder)\n",
    "        random.shuffle(name_list)\n",
    "        test_size = int(len(name_list) / K)\n",
    "        test_names = name_list[fold*test_size:(fold+1)*test_size]\n",
    "        train_names = list(set(name_list)-set(test_names))\n",
    "        tatol_test_names.append(test_names)\n",
    "        tatol_train_names.append(train_names)\n",
    "    return tatol_train_names, tatol_test_names\n",
    "\n",
    "def load_original_data_K_fold(K=5):\n",
    "    for i in range(0, K):\n",
    "        train_names, test_names = K_fold_split(K, fold=i)\n",
    "        print('loading data %dfold No%d'%(K,i))\n",
    "        train_data = [load_data(train_names[i]) for i in range(0,11)]\n",
    "        test_data = [load_data(test_names[i]) for i in range(0,11)]\n",
    "        original_dataset = (train_data, test_data)\n",
    "        f = open('data/original_dataset_%dfold_No%d'%(K,i), 'wb')\n",
    "        pickle.dump(original_dataset, f)\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import create_dataset\n",
    "import os\n",
    "\n",
    "def create_dataset_K_fold(K=5):\n",
    "    for i in range(0, K):\n",
    "        original_dataset = 'data/original_dataset_%dfold_No%d'%(K,i)\n",
    "        f = open(original_dataset, 'rb')\n",
    "        train_data, test_data = pickle.load(f)\n",
    "        val_data = test_data #为了方便调用之前写好的代码\n",
    "        f.close()\n",
    "        for bag in range(0,10):\n",
    "            print('generating data fold_No%d bag No%d'%(i,bag))\n",
    "            create_dataset(original_dataset,2500, down_sample=True, instance=bag,\n",
    "                use_pre_load=True, pre_loaded = (train_data, val_data, test_data))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data 5fold No0\n",
      "load 3460 files\n",
      "load 3002 files\n",
      "load 402 files\n",
      "load 137 files\n",
      "load 15043 files\n",
      "load 3608 files\n",
      "load 2909 files\n",
      "load 1029 files\n",
      "load 118 files\n",
      "load 123 files\n",
      "load 123 files\n",
      "load 865 files\n",
      "load 750 files\n",
      "load 100 files\n",
      "load 34 files\n",
      "load 3760 files\n",
      "load 901 files\n",
      "load 727 files\n",
      "load 257 files\n",
      "load 29 files\n",
      "load 30 files\n",
      "load 30 files\n",
      "loading data 5fold No1\n",
      "load 3460 files\n",
      "load 3002 files\n",
      "load 402 files\n",
      "load 137 files\n",
      "load 15043 files\n",
      "load 3608 files\n",
      "load 2909 files\n",
      "load 1029 files\n",
      "load 118 files\n",
      "load 123 files\n",
      "load 123 files\n",
      "load 865 files\n",
      "load 750 files\n",
      "load 100 files\n",
      "load 34 files\n",
      "load 3760 files\n",
      "load 901 files\n",
      "load 727 files\n",
      "load 257 files\n",
      "load 29 files\n",
      "load 30 files\n",
      "load 30 files\n",
      "loading data 5fold No2\n",
      "load 3460 files\n",
      "load 3002 files\n",
      "load 402 files\n",
      "load 137 files\n",
      "load 15043 files\n",
      "load 3608 files\n",
      "load 2909 files\n",
      "load 1029 files\n",
      "load 118 files\n",
      "load 123 files\n",
      "load 123 files\n",
      "load 865 files\n",
      "load 750 files\n",
      "load 100 files\n",
      "load 34 files\n",
      "load 3760 files\n",
      "load 901 files\n",
      "load 727 files\n",
      "load 257 files\n",
      "load 29 files\n",
      "load 30 files\n",
      "load 30 files\n",
      "loading data 5fold No3\n",
      "load 3460 files\n",
      "load 3002 files\n",
      "load 402 files\n",
      "load 137 files\n",
      "load 15043 files\n",
      "load 3608 files\n",
      "load 2909 files\n",
      "load 1029 files\n",
      "load 118 files\n",
      "load 123 files\n",
      "load 123 files\n",
      "load 865 files\n",
      "load 750 files\n",
      "load 100 files\n",
      "load 34 files\n",
      "load 3760 files\n",
      "load 901 files\n",
      "load 727 files\n",
      "load 257 files\n",
      "load 29 files\n",
      "load 30 files\n",
      "load 30 files\n",
      "loading data 5fold No4\n",
      "load 3460 files\n",
      "load 3002 files\n",
      "load 402 files\n",
      "load 137 files\n",
      "load 15043 files\n",
      "load 3608 files\n"
     ]
    }
   ],
   "source": [
    "load_original_data_K_fold()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "686e52782356fa5192d8da796457d9836a4bb6aebab3dc056991bb89ef60f4a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
